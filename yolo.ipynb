{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO\n",
    "\n",
    "\n",
    "To download the COCO dataset (http://cocodataset.org/#download):\n",
    "\n",
    "    Train Images: http://images.cocodataset.org/zips/train2014.zip\n",
    "    Validation Images: http://images.cocodataset.org/zips/val2014.zip\n",
    "    Annotations (Train+Val):  http://images.cocodataset.org/annotations/annotations_trainval2014.zip \n",
    "    \n",
    "    Run this script to convert annotations in COCO format to VOC format: https://gist.github.com/chicham/6ed3842d0d2014987186#file-coco2pascal-py\n",
    "    Download pre-trained weights from: https://pjreddie.com/media/files/yolo.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Reshape, Activation, BatchNormalization\n",
    "from keras.layers import  Input, Conv2D, MaxPooling2D\n",
    "from keras.layers import Flatten, Dense, Lambda\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers.merge import concatenate\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import cv2\n",
    "from preprocessing import parse_annotation, BatchGenerator\n",
    "from utils import WeightReader, decode_netout, draw_boxes\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize\n",
    "LABELS = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "IMAGE_H, IMAGE_W = 416, 416\n",
    "GRID_H, GRID_W = 13, 13\n",
    "BOX = 5\n",
    "CLASS = len(LABELS)\n",
    "CLASS_WEIGHTS = np.ones(CLASS, dtype=\"float32\")\n",
    "OBJ_THRESHOLD = 0.3\n",
    "NMS_THRESHOLD = 0.3\n",
    "ANCHORS = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]\n",
    "\n",
    "NO_OBJECT_SCALE = 1.0\n",
    "OBJECT_SCALE = 5.0\n",
    "COORD_SCALE = 1.0\n",
    "CLASS_SCALE = 1.0\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "WARM_UP_BATCHES = 0\n",
    "TRUE_BOX_BUFFER = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wt_path = 'dataset/yolov2.weights'\n",
    "train_image_folder = 'dataset/train2014/'\n",
    "train_annot_folder = 'dataset/train2014ann/'\n",
    "valid_image_folder = 'dataset/val2014/'\n",
    "valid_annot_folder = 'dataset/val2014ann/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def space_to_depth_x2(x):\n",
    "    return tf.space_to_depth(x, block_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_image = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
    "true_boxes = Input(shape=(1, 1, 1, TRUE_BOX_BUFFER, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Layer 1\n",
    "x = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\n",
    "x = BatchNormalization(name ='norm_1')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "#Layer 2\n",
    "x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_2')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "#Layer 3\n",
    "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_3')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "#Layer 4\n",
    "x = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_4', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_4')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "#Layer 5\n",
    "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_5')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "#Layer 6\n",
    "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_6')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "#Layer 7\n",
    "x = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_7')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "#Layer 8\n",
    "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_8')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "#Layer 9\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_9')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "#Layer 10\n",
    "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_10')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "#Layer 11\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_11')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "#Layer 12\n",
    "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_12')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "#Layer 13\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_13')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "x2 = x\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "#Layer 14\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_14')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "#Layer 15\n",
    "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_15')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "#Layer 16\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_16')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "#Layer 17\n",
    "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_17')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "#Layer 18\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_18')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "#Layer 19\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_19')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "#Layer 20\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_20')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 21\n",
    "x2 = Conv2D(64, (1,1),strides=(1,1), padding='same', name='conv_21', use_bias=False)(x2)\n",
    "x2 = BatchNormalization(name='norm_21')(x2)\n",
    "x2 = LeakyReLU(alpha=0.1)(x2)\n",
    "x2 = Lambda(space_to_depth_x2)(x2)\n",
    "\n",
    "x = concatenate([x2, x])\n",
    "\n",
    "#Layer 22\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_22')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "#Layer 23\n",
    "x = Conv2D(BOX*(4+1+CLASS), (1,1), strides=(1,1), padding='same', name='conv_23')(x)\n",
    "output = Reshape((GRID_H, GRID_W, BOX, 4+1+CLASS))(x)\n",
    "\n",
    "#still need to figure out the utility of this part\n",
    "output = Lambda(lambda args: args[0])([output, true_boxes])\n",
    "\n",
    "model = Model([input_image, true_boxes], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 416, 416, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 416, 416, 32) 864         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_1 (BatchNormalization)     (None, 416, 416, 32) 128         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, 416, 416, 32) 0           norm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 208, 208, 32) 0           leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 208, 208, 64) 18432       max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "norm_2 (BatchNormalization)     (None, 208, 208, 64) 256         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)      (None, 208, 208, 64) 0           norm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 104, 104, 64) 0           leaky_re_lu_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 104, 104, 128 73728       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "norm_3 (BatchNormalization)     (None, 104, 104, 128 512         conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)      (None, 104, 104, 128 0           norm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 104, 104, 64) 8192        leaky_re_lu_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_4 (BatchNormalization)     (None, 104, 104, 64) 256         conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)      (None, 104, 104, 64) 0           norm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Conv2D)                 (None, 104, 104, 128 73728       leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_5 (BatchNormalization)     (None, 104, 104, 128 512         conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)      (None, 104, 104, 128 0           norm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 52, 52, 128)  0           leaky_re_lu_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_6 (Conv2D)                 (None, 52, 52, 256)  294912      max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "norm_6 (BatchNormalization)     (None, 52, 52, 256)  1024        conv_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)      (None, 52, 52, 256)  0           norm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_7 (Conv2D)                 (None, 52, 52, 128)  32768       leaky_re_lu_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_7 (BatchNormalization)     (None, 52, 52, 128)  512         conv_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)      (None, 52, 52, 128)  0           norm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_8 (Conv2D)                 (None, 52, 52, 256)  294912      leaky_re_lu_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_8 (BatchNormalization)     (None, 52, 52, 256)  1024        conv_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)      (None, 52, 52, 256)  0           norm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 26, 26, 256)  0           leaky_re_lu_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_9 (Conv2D)                 (None, 26, 26, 512)  1179648     max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "norm_9 (BatchNormalization)     (None, 26, 26, 512)  2048        conv_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)      (None, 26, 26, 512)  0           norm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_10 (Conv2D)                (None, 26, 26, 256)  131072      leaky_re_lu_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_10 (BatchNormalization)    (None, 26, 26, 256)  1024        conv_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)      (None, 26, 26, 256)  0           norm_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_11 (Conv2D)                (None, 26, 26, 512)  1179648     leaky_re_lu_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_11 (BatchNormalization)    (None, 26, 26, 512)  2048        conv_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)      (None, 26, 26, 512)  0           norm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_12 (Conv2D)                (None, 26, 26, 256)  131072      leaky_re_lu_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_12 (BatchNormalization)    (None, 26, 26, 256)  1024        conv_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)      (None, 26, 26, 256)  0           norm_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_13 (Conv2D)                (None, 26, 26, 512)  1179648     leaky_re_lu_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_13 (BatchNormalization)    (None, 26, 26, 512)  2048        conv_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)      (None, 26, 26, 512)  0           norm_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 13, 13, 512)  0           leaky_re_lu_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_14 (Conv2D)                (None, 13, 13, 1024) 4718592     max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "norm_14 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_15 (Conv2D)                (None, 13, 13, 512)  524288      leaky_re_lu_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_15 (BatchNormalization)    (None, 13, 13, 512)  2048        conv_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)      (None, 13, 13, 512)  0           norm_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_16 (Conv2D)                (None, 13, 13, 1024) 4718592     leaky_re_lu_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_16 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_17 (Conv2D)                (None, 13, 13, 512)  524288      leaky_re_lu_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_17 (BatchNormalization)    (None, 13, 13, 512)  2048        conv_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)      (None, 13, 13, 512)  0           norm_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_18 (Conv2D)                (None, 13, 13, 1024) 4718592     leaky_re_lu_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_18 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_19 (Conv2D)                (None, 13, 13, 1024) 9437184     leaky_re_lu_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_19 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_21 (Conv2D)                (None, 26, 26, 64)   32768       leaky_re_lu_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_21 (BatchNormalization)    (None, 26, 26, 64)   256         conv_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_20 (Conv2D)                (None, 13, 13, 1024) 9437184     leaky_re_lu_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_54 (LeakyReLU)      (None, 26, 26, 64)   0           norm_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_20 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 13, 13, 256)  0           leaky_re_lu_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_53 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 13, 13, 1280) 0           lambda_2[0][0]                   \n",
      "                                                                 leaky_re_lu_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_22 (Conv2D)                (None, 13, 13, 1024) 11796480    concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_22 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_55 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_23 (Conv2D)                (None, 13, 13, 425)  435625      leaky_re_lu_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 13, 13, 5, 85 0           conv_23[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1, 1, 1, 50,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 13, 13, 5, 85 0           reshape_1[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 50,983,561\n",
      "Trainable params: 50,962,889\n",
      "Non-trainable params: 20,672\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load pre-trained weights\n",
    "weight_reader = WeightReader(wt_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_reader.reset() # Reset the weights\n",
    "nb_conv = 23 # number of layers\n",
    "\n",
    "for i in range(1, nb_conv+1): # 1 to 23 for this model\n",
    "    #Extract each conv layer at a time\n",
    "    conv_layer = model.get_layer('conv_' + str(i)) \n",
    "    \n",
    "    # For every layer but the final one\n",
    "    if i < nb_conv:\n",
    "        # Fetch the Batch normalization layer as well\n",
    "        norm_layer = model.get_layer('norm_' + str(i))\n",
    "        \n",
    "        # This will equal to the number of filters used in this layer\n",
    "        size = np.prod(norm_layer.get_weights()[0].shape)\n",
    "\n",
    "        #Read the weights from the weights file\n",
    "        beta = weight_reader.read_bytes(size)\n",
    "        gamma = weight_reader.read_bytes(size)\n",
    "        mean = weight_reader.read_bytes(size)\n",
    "        variance = weight_reader.read_bytes(size)\n",
    "        \n",
    "        weights = norm_layer.set_weights([gamma, beta, mean, variance])\n",
    "    \n",
    "    if len(conv_layer.get_weights()) > 1:\n",
    "        bias = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
    "        # Read the weights for that kernel\n",
    "        kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "        #Reshape the kernel e.g. for Conv_1 from (864,) to (32, 3, 3, 3)\n",
    "        kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "        #Transpose the kernel e.g for Conv_1 from (32, 3, 3, 3) to (3, 3, 3, 32)\n",
    "        kernel = kernel.transpose([2,3,1,0])\n",
    "        #Set the weights\n",
    "        conv_layer.set_weights([kernel, bias])\n",
    "    else:\n",
    "        kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "        kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "        kernel = kernel.transpose([2,3,1,0])\n",
    "        conv_layer.set_weights([kernel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize weights of the last layer\n",
    "layer = model.layers[-4] #-4 denotes the last conv layer (check model summary)\n",
    "weights = layer.get_weights()\n",
    "# Use random normal distribution divided by the grid size to initialize the kernel and bias\n",
    "new_kernel = np.random.normal(size = weights[0].shape)/(GRID_H*GRID_W)\n",
    "new_bias = np.random.normal(size = weights[1].shape)/(GRID_H*GRID_W)\n",
    "\n",
    "layer.set_weights([new_kernel, bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the custom loss function\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    mask_shape = tf.shape(y_true)[:4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
